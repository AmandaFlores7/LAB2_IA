{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio de Datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos, librerias y creación de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset redWine y whiteWine\n",
    "redWine = pd.read_csv('winequality-red.csv', sep=';')\n",
    "whiteWine = pd.read_csv('winequality-white.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para mostrar histograma y boxplot de un atributo\n",
    "def histograma_boxplot(dataset, atributo):\n",
    "  plt.figure(figsize=(10,4))\n",
    "\n",
    "  plt.subplot(1,2,1)\n",
    "  sns.histplot(dataset[atributo])\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  sns.boxplot(data=dataset[atributo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion deteccion de outliers\n",
    "def deteccion_outliers(dataset):\n",
    "  cols = dataset.columns\n",
    "  for i in cols:\n",
    "    if i == 'type':\n",
    "      continue\n",
    "    q1 = dataset[i].quantile(0.25)\n",
    "    q3 = dataset[i].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lim_inf = q1 - 1.5 * iqr\n",
    "    lim_sup = q3 + 1.5 * iqr\n",
    "    outliers = dataset[(dataset[i] < lim_inf) | (dataset[i] > lim_sup)].shape[0]\n",
    "    print(f\"El atributo {i} tiene {outliers} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion resumen de datos\n",
    "def resumen_datos(dataset):\n",
    "  print(\"Cantidad de datos en wine: \", dataset.shape[0])\n",
    "  print(\"Calidad media de vinos: \", dataset['quality'].mean())\n",
    "  print(\"Cantidad de vinos con calidad mayor a la media: \", dataset[dataset['quality'] > dataset['quality'].mean()].shape[0])\n",
    "  print(\"Cantidad de vinos con calidad menor a la media: \", dataset[dataset['quality'] < dataset['quality'].mean()].shape[0])\n",
    "  print(\"La desviacion estandar de la calidad de los vinos es: \", dataset['quality'].std())\n",
    "  print(\"La calidad minima de los vinos es: \", dataset['quality'].min())\n",
    "  print(\"La calidad maxima de los vinos es: \", dataset['quality'].max())\n",
    "  print(\"El 25% de los vinos tiene una calidad menor a: \", dataset['quality'].quantile(0.25))\n",
    "  print(\"El 75% de los vinos tiene una calidad mayor a: \", dataset['quality'].quantile(0.75))\n",
    "  print(\"El ultimo 25% de los vinos tiene una calidad entre \", dataset['quality'].quantile(0.25), \" y \", dataset['quality'].quantile(0.75))\n",
    "  print(\"La mayor concentracion de vinos se encuentra entre \", dataset['quality'].quantile(0.25), \" y \", dataset['quality'].quantile(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion detección de asimetria\n",
    "def deteccion_asimetria(dataset):\n",
    "  cols = dataset.columns\n",
    "  for i in cols:\n",
    "    if i == 'type':\n",
    "      continue\n",
    "    print(f\"El atributo {i} tiene una asimetria de {dataset[i].skew()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion mostrar mayor correlacion entre atributos\n",
    "def mayor_correlacion(dataset, max_valor = 0, atributo = ''):\n",
    "  corr = dataset.corr()\n",
    "  if atributo != '':\n",
    "    corr_quality = corr[[atributo]].copy()\n",
    "    corr_quality['abs_corr'] = corr_quality[atributo].abs()\n",
    "    corr_quality = corr_quality[corr_quality['abs_corr'] != 1]  # Excluir correlaciones igual a 1\n",
    "    corr_quality = corr_quality.sort_values('abs_corr', ascending=False).head(3)\n",
    "\n",
    "    print(corr_quality)\n",
    "  elif max_valor != 0:\n",
    "    max_valor = abs(max_valor)\n",
    "    high_corr = corr[(corr > max_valor) | (corr < -max_valor)]\n",
    "    high_corr = high_corr.stack().reset_index()\n",
    "    high_corr['abs_corr'] = high_corr[0].abs()\n",
    "    high_corr = high_corr[high_corr[0] != 1]  # Filtrar correlaciones diferentes de 1\n",
    "    high_corr = high_corr.sort_values('abs_corr', ascending=False).drop_duplicates(0)\n",
    "    print(high_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de los datos de Red Wine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observar dataset redWine\n",
    "redWine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de datos en redWine y whiteWine\n",
    "print(\"Cantidad de datos en redWine: \", redWine.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos en redWine\n",
    "print(\"Red Wine:\")\n",
    "redWine.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que no es necesario hacer algun cambio en los datos, ya que no hay datos categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de datos en relacion de RedWine en base al atributo 'quality'\n",
    "resumen_datos(redWine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos de Histogramas y Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidades de vinos por calidad\n",
    "sns.countplot(x='quality', data=redWine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por cada atributo, mostrar histograma y boxplot\n",
    "for atributo in redWine.columns:\n",
    "  histograma_boxplot(redWine, atributo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deteccion de outliers en wine\n",
    "deteccion_outliers(redWine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis Asimetrías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar asimetria en redWine\n",
    "deteccion_asimetria(redWine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Correlaciones entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de correlación de Pearson\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(redWine.corr(method='pearson'), annot=True, cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos con mayor correlacion entre ellos\n",
    "mayor_correlacion(redWine, max_valor=0.6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Correlaciones en relacion a la variable Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlacion con la variable 'quality' del dataset wine a través de un mapa de calor\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(redWine.corr()[['quality']], annot=True, cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos con mayor correlacion con 'quality'\n",
    "mayor_correlacion(redWine, atributo='quality')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de los datos de White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observar dataset WhiteWine\n",
    "whiteWine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de datos en whiteWine\n",
    "print(\"Cantidad de datos en redWine: \", whiteWine.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos en WhiteWine\n",
    "print(\"White Wine:\")\n",
    "whiteWine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que no es necesario hacer algun cambio en los datos, ya que no hay datos categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de datos en relacion de WhiteWine en base al atributo 'quality'\n",
    "resumen_datos(whiteWine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos de Histogramas y Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidades de vinos por calidad\n",
    "sns.countplot(x='quality', data=whiteWine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por cada atributo, mostrar histograma y boxplot\n",
    "for atributo in whiteWine.columns:\n",
    "  histograma_boxplot(whiteWine, atributo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deteccion de outliers en wine\n",
    "deteccion_outliers(whiteWine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis Asimetrías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar asimetria en redWine\n",
    "deteccion_asimetria(whiteWine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Correlaciones entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de correlación de Pearson\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(whiteWine.corr(method='pearson'), annot=True, cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos con mayor correlacion entre ellos\n",
    "mayor_correlacion(whiteWine, max_valor=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Correlaciones en relacion a la variable Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlacion con la variable 'quality' del dataset wine a través de un mapa de calor\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(whiteWine.corr()[['quality']], annot=True, cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos con mayor correlacion con 'quality'\n",
    "mayor_correlacion(whiteWine, atributo='quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de costo\n",
    "def compute_cost(X, y, theta, theta_0):\n",
    "    m = len(y)\n",
    "    predictions = X.dot(theta) + theta_0\n",
    "    cost = (1/(2*m)) * np.sum((predictions - y)**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Gradient Descent\n",
    "def batch_gradient_descent(X_train, y_train, X_test, y_test, theta, theta_0, alpha, num_iters):\n",
    "  m_train = len(y_train)\n",
    "  m_test = len(y_test)\n",
    "  cost_history_train = []\n",
    "  cost_history_test = []\n",
    "  for i in range(num_iters):\n",
    "    # Entrenamiento\n",
    "    predictions_train = X_train.dot(theta) + theta_0\n",
    "    theta = theta - (alpha/m_train) * X_train.T.dot(predictions_train - y_train)\n",
    "    theta_0 = theta_0 - (alpha/m_train) * np.sum(predictions_train - y_train)\n",
    "    cost_train = compute_cost(X_train, y_train, theta, theta_0)\n",
    "    cost_history_train.append(cost_train)\n",
    "    # Prueba\n",
    "    predictions_test = X_test.dot(theta) + theta_0\n",
    "    cost_test = compute_cost(X_test, y_test, theta, theta_0)\n",
    "    cost_history_test.append(cost_test)\n",
    "  return theta, theta_0, cost_history_train, cost_history_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion de regresion lineal simple usand batch gradient descent para determinar la calidad del vino\n",
    "def regresion_lineal_simple(dataSet, atributo, alpha, num_iters):\n",
    "  # Selección de variables de entrada y salida\n",
    "  X = dataSet[[atributo]].values\n",
    "  Y = dataSet['quality'].values\n",
    "  \n",
    "  # Separación aleatoria de los datos en entrenamiento y prueba\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "  # Normalización de los datos de entrada\n",
    "  mu = np.mean(X_train, axis=0)\n",
    "  sigma = np.std(X_train, axis=0)\n",
    "  X_train_norm = (X_train - mu) / sigma\n",
    "  X_test_norm = (X_test - mu) / sigma\n",
    "\n",
    "  # Inicialización de parámetros\n",
    "  theta = np.zeros(X_train_norm.shape[1])\n",
    "  theta_0 = 0\n",
    "  \n",
    "  # Ejecución de Batch Gradient Descent\n",
    "  theta_final, theta_0_final, cost_history_train, cost_history_test = batch_gradient_descent(X_train_norm, y_train, X_test_norm, y_test, theta, theta_0, alpha, num_iters)\n",
    "\n",
    "  # Predicción en el conjunto de prueba\n",
    "  y_pred = X_test_norm.dot(theta_final) + theta_0_final\n",
    "\n",
    "  # Cálculo de R y R cuadrado\n",
    "  r = np.corrcoef(y_test, y_pred)[0,1]\n",
    "  r_squared = r**2\n",
    "\n",
    "  # Impresión de resultados\n",
    "  print('Valor de R:', r)\n",
    "  print('Valor de R cuadrado:', r_squared)\n",
    "  print('Theta:', theta_final)\n",
    "  print('Costo de entrenamiento:', cost_history_train[-1])\n",
    "  print('Costo de prueba:', cost_history_test[-1])\n",
    "\n",
    "  # Gráfica de la función de costo vs el número de iteraciones\n",
    "  plt.plot(range(num_iters), cost_history_train, label='Entrenamiento')\n",
    "  plt.plot(range(num_iters), cost_history_test, label='Prueba')\n",
    "  plt.xlabel('Número de iteraciones')\n",
    "  plt.ylabel('Costo')\n",
    "  plt.title('Función de costo vs Número de iteraciones')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  # Gráfica de los valores reales vs predicciones en el conjunto de prueba\n",
    "  plt.scatter(y_test, y_pred)\n",
    "  plt.xlabel('Valores reales')\n",
    "  plt.ylabel('Predicciones')\n",
    "  plt.title('Valores reales vs Predicciones')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal simple usando batch gradient descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el Red Wine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_simple(redWine, 'alcohol', 0.01, 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Acidez Volatil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_simple(redWine, 'volatile acidity', 0.01, 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Sufates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_simple(redWine, 'sulphates', 0.01, 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_simple(whiteWine, 'alcohol', 0.01, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Acidez Volatil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_simple(whiteWine, 'volatile acidity', 0.01, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Sufates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_simple(whiteWine, 'sulphates', 0.01, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion lineal simple usando stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el White Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Acidez Volatil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Acidez Volatil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el atributo Density"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de los resultados para White Wine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de los resultados para Red Wine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTRAS WEAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Selección de variables de entrada y salida\n",
    "X = wine[['alcohol']].values\n",
    "Y = wine['quality'].values\n",
    "\n",
    "# Separación aleatoria de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalización de los datos de entrada\n",
    "X_train_norm = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "\n",
    "# Agregando columna de unos a X_train_norm para el término de sesgo (bias)\n",
    "X_train_norm = np.c_[np.ones(X_train_norm.shape[0]), X_train_norm]\n",
    "\n",
    "# Creación del modelo en TensorFlow\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, activation=None, input_shape=(X_train_norm.shape[1],))\n",
    "])\n",
    "\n",
    "# Definición de la función de costo y optimizador\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# Configuración del bucle de entrenamiento\n",
    "num_iterations = 1000\n",
    "batch_size = 32\n",
    "train_loss_history = []\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for iteration in range(num_iterations):\n",
    "    indices = np.random.choice(X_train_norm.shape[0], batch_size, replace=False)\n",
    "    X_batch = X_train_norm[indices]\n",
    "    y_batch = y_train[indices]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(X_batch, training=True)\n",
    "        loss_value = loss_fn(y_batch, predictions)\n",
    "\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    train_loss_history.append(loss_value.numpy())\n",
    "\n",
    "# Mostrar resultados\n",
    "theta = model.get_weights()[0]\n",
    "theta_0 = model.get_weights()[1]\n",
    "print('Theta:', theta)\n",
    "print('Theta_0:', theta_0)\n",
    "print('Costo de entrenamiento:', train_loss_history[-1])\n",
    "\n",
    "# Gráfica de la función de costo vs el número de iteraciones\n",
    "plt.plot(range(num_iterations), train_loss_history)\n",
    "plt.xlabel('Número de iteraciones')\n",
    "plt.ylabel('Costo')\n",
    "plt.title('Función de costo vs Número de iteraciones')\n",
    "plt.show()\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "X_test_norm = (X_test - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "X_test_norm = np.c_[np.ones(X_test_norm.shape[0]), X_test_norm]\n",
    "y_pred = model.predict(X_test_norm)\n",
    "\n",
    "# Gráfica de los valores reales vs predicciones en el conjunto de prueba\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Valores reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Valores reales vs Predicciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Selección de variables de entrada y salida\n",
    "X = wine[['alcohol', 'density', 'sulphates']].values\n",
    "Y = wine['quality'].values\n",
    "\n",
    "# Separación aleatoria de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# normalizando datos de entrada\n",
    "X_train_norm = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "\n",
    "# agregando columna de unos a X_train_norm para el término de sesgo (bias)\n",
    "X_train_norm = np.c_[np.ones(X_train_norm.shape[0]), X_train_norm]\n",
    "\n",
    "# convirtiendo y_train a una matriz de forma (320,1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "# definición de función de costo para regresión lineal\n",
    "def compute_cost3(X, y, theta):\n",
    "    m = len(y)\n",
    "    predictions = X.dot(theta)\n",
    "    cost = (1 / (2 * m)) * np.sum(np.square(predictions - y))\n",
    "    return cost\n",
    "\n",
    "# definición de función de gradiente para regresión lineal\n",
    "def compute_gradient(X, y, theta):\n",
    "    m = len(y)\n",
    "    predictions = X.dot(theta)\n",
    "    gradient = (1 / m) * X.T.dot(predictions - y)\n",
    "    return gradient\n",
    "\n",
    "# definición de función de gradiente estocástico para regresión lineal\n",
    "def stochastic_gradient(X, y, theta, alpha, num_iterations):\n",
    "    m = len(y)\n",
    "    J_history = np.zeros(num_iterations)\n",
    "    for iteration in range(num_iterations):\n",
    "        for i in range(m):\n",
    "            rand_ind = np.random.randint(0, m)\n",
    "            X_i = X[rand_ind, :].reshape(1, X.shape[1])\n",
    "            y_i = y[rand_ind].reshape(1, 1)\n",
    "            prediction = np.dot(X_i, theta)\n",
    "            gradient = compute_gradient(X_i, y_i, theta)\n",
    "            theta = theta - alpha * gradient\n",
    "        J_history[iteration] = compute_cost3(X, y, theta)\n",
    "    return theta, J_history\n",
    "\n",
    "# entrenando modelo\n",
    "theta = np.zeros((X_train_norm.shape[1], 1))\n",
    "alpha = 0.01\n",
    "num_iterations = 1000\n",
    "theta, J_history = stochastic_gradient(X_train_norm, y_train, theta, alpha, num_iterations)\n",
    "\n",
    "# mostrando resultados\n",
    "print(f\"Theta final: \\n{theta}\")\n",
    "print(f\"Costo final de entrenamiento: {J_history[-1]}\")\n",
    "\n",
    "# graficando costo vs. iteraciones\n",
    "plt.plot(J_history)\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.ylabel(\"Costo\")\n",
    "plt.show()\n",
    "\n",
    "# Gráfica de los valores reales vs predicciones en el conjunto de prueba\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Valores reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Valores reales vs Predicciones')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
